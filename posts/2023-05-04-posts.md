---
title: LangChain & OpenAI
description: Today I learned about LangChain
slug: openai-langchain
<!--- authors:
  - name: David Windham
    title: Something Else
    url: https://davidawindham.com
    image_url: https://davidawindham.com/wp-content/themes/daw/img/opengraph_image.jpg -->
tags: [AI,ML,LLM,ChatGPT]
image: https://davidawindham.com/wp-content/themes/daw/img/opengraph_image.jpg
hide_table_of_contents: false
---

Today I learned how the integrate LangChain into the OpenAI API. Since it was quite a bit to wrap my head around, I also had to do the deep dive on some of the fundamentals of machine learning and vector databases. I published a simple demo and started making notes about the process.

<!--truncate-->

I've started making notes and related resources @ [/docs/sass/openai](/docs/saas/openai) <sub>1</sub>. I also put up a simple demo @ [https://jenks.davidawindham.com](https://jenks.davidawindham.com) <sub>2</sub> that uses a doctoral dissertation from a friend who teaches computer science locally. It's powered by the OpenAI API, LangChain, and a Pinecone vector database. 

I'm about halfway done with a course ChatGPT Prompt Engineering for Developers<sub>3</sub>, and I spent a couple hours on the phone talking with a fellow who has a very deep understanding of machine learning and artificial intelligence. It was mostly me asking him to explain some of these to me:

- why did my vector database use a cosine metric and what does trigonometry have to do with machine learning?
- what are vector dimensions and how to they related to machine learning
- how are artificial neural networks built
- how are linear regressions used in machine learning
- how are weights and dimensions added to models.

It's all quite a bit to take in. My brain was lit ðŸ”¥ on LangChain, so I spent a good hour just decompressing. I still feel a bit like I did when I first started learning programming in that I have such a naive knowledge of the fundamentals. In the last couple of weeks, I've spent a good bit of time just getting reacquainted with Python development environments like Jupyter, Colab, Tensorflow, and PyTorch. I don't think I'll ever be building neural networks, but I would at least like to know how it's done so that the training, chaining, prompting, transformers, and pipelines will become easier for me to use. 

Although I can see some really practical applications, I think my first custom project will likely be an absurd AI chatbot built on top of my personal chats, emails, calendar, this knowledge-base, and my website<sub>4</sub>. My wife and I were discussing AI a couple days ago and our biggest takeaway is that when systematic knowledge like that of a Jeopardy contestant becomes less impressive, the more that our personal human qualities like emotion and artistic creativity become important.

---

1. Docs / SAAS / OpenAI  - [/docs/saas/openai](/docs/saas/openai)
2. TedBot - [https://jenks.davidawindham.com](https://jenks.davidawindham.com)
3. ChatGPT Prompt Engineering for Developers - https://learn.deeplearning.ai/chatgpt-prompt-eng/
4. A Second Brain - https://davidawindham.com/a-second-brain/
